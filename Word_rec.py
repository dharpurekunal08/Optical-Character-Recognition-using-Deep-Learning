# -*- coding: utf-8 -*-
"""Word_Rec.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1wT6ydffIgr9vUadtYw35MMRhquVOS_vE
"""

import tensorflow as tf
tf.test.gpu_device_name()

!pip install -U -q PyDrive
 
from pydrive.auth import GoogleAuth
from pydrive.drive import GoogleDrive
from google.colab import auth
from oauth2client.client import GoogleCredentials
 
# 1. Authenticate and create the PyDrive client.
auth.authenticate_user()
gauth = GoogleAuth()
gauth.credentials = GoogleCredentials.get_application_default()
drive = GoogleDrive(gauth)

file_list = drive.ListFile({'q': "'1iW1GMIWmDm6h6uGxJPjk2bt-7JcQJETM' in parents and trashed=false"}).GetList()
for file1 in file_list:
  print('title: %s, id: %s' % (file1['title'], file1['id']))

train_x = drive.CreateFile({'id': '1Ni7vZ53ssxLTP5-J8Zv3svn6L9W-YpEM'})
train_x.GetContentFile('Train_X.csv')
train_y = drive.CreateFile({'id': '1hkIEneGvbb3QJ_UMPioNxPF1PT1MdZqr'})
train_y.GetContentFile('Train_Y.csv')

import numpy as np
import keras
import matplotlib.pyplot as plt
import pandas as pd
import os

data = pd.read_csv("Train_X.csv").values
X_train = data[:, 1:]
data = pd.read_csv("Train_Y.csv").values
Y = data[:, 1:]
X_train = np.reshape(X_train, (X_train.shape[0], 64, 64, 1)) / 255
#Y = np.reshape(Y, (Y.shape[0], Y.shape[1], 1))
print(X_train.shape)
print(Y.shape)

Y_train = np.zeros((Y.shape[0], Y.shape[1], 53))
for i in range(Y_train.shape[0]) :
  for j in range(Y_train[i].shape[0]) :
    arr = np.zeros((53))
    c = int(Y[i][j])
    arr[c] = 1
    Y_train[i][j] = arr
    
print(Y_train.shape)

from keras.layers import Input, Conv2D, BatchNormalization, MaxPooling2D, Activation, LSTM, Flatten, Dense, Dropout, TimeDistributed, RepeatVector
def make_model(input_shape) :
  X = keras.models.Sequential()
  X.add(Conv2D(16, (3, 3), padding = 'same', input_shape = input_shape))
  X.add(BatchNormalization())
  X.add(Activation('relu'))
  X.add(MaxPooling2D((3, 3)))
  
  X.add(Conv2D(32, (3, 3), padding = 'same'))
  X.add(BatchNormalization())
  X.add(Activation('relu'))
  X.add(MaxPooling2D((3, 3)))
  
  X.add(Conv2D(64, (3, 3), padding = 'same'))
  X.add(BatchNormalization())
  X.add(Activation('relu'))
  X.add(MaxPooling2D((3, 3)))
  X.add(Flatten())
  #X.add(keras.layers.Reshape((16, 16)))
  #X_input = Input((16, 16))
  #time = TimeDistributed(X)(X_input)
  X.add(RepeatVector(10))
  X.add(LSTM(64, return_sequences = True))
  X.add(Dense(53, activation = 'softmax'))
  
  
  X.summary()
  return X
  

model = make_model((64, 64, 1))

model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])
model.fit(X_train, Y_train, batch_size = 512, epochs = 20, validation_split = 0.05)

